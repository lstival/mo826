{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3df4aef",
   "metadata": {},
   "source": [
    "# Fabrício Ferreira da Silva RA: 231900 e Leandro Stival RA: 263013"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d0fb0",
   "metadata": {},
   "source": [
    "## Descrição\n",
    "Notebook contendo a criação de um SVM para classificar imagens de resonância em EM ou AVC, treinamento realizando com o conjunto gerado através das imagens fornecidas, que foram normalizadas utilizando uma quantização para 30 tons de cinza e posterioremente tiveram suas *features* extraídas de forma manual e salvas em arquivos *.csv* que foram carregados unidos, normalizados e separados em treino e validação.\n",
    "<br><br>\n",
    "O treinamento foi realizado utilizando o ajuste fino de parâmetros para criar o melhor modelo possível, e a sua avaliação com os dados de validação foi realizado com a acurácia balanceada junto de uma matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebd95fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "#Lib para importar o SVM\n",
    "from sklearn.svm import SVC\n",
    "#Lib para separar treino e validação\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Libs para tratamento dos dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537c5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fator para o tamanho do conjunto de teste\n",
    "TEST_FACTOR = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa3840",
   "metadata": {},
   "source": [
    "## Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd18f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_df(df):\n",
    "#     \"\"\"\n",
    "#     Recebe um conjunto de dados e retorna o seu valor normalizado\n",
    "#     \"\"\"\n",
    "#     df_norm = (df-df.min())/(df.max()-df.min())\n",
    "#     return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531c2f2",
   "metadata": {},
   "source": [
    "### Conjunto de dados EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f831eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrast</th>\n",
       "      <th>dissimilarity</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>ASM</th>\n",
       "      <th>energy</th>\n",
       "      <th>correlation</th>\n",
       "      <th>SRE</th>\n",
       "      <th>LRE</th>\n",
       "      <th>GLU</th>\n",
       "      <th>RLU</th>\n",
       "      <th>RPC</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246.643915</td>\n",
       "      <td>11.979190</td>\n",
       "      <td>0.799157</td>\n",
       "      <td>0.361724</td>\n",
       "      <td>0.601435</td>\n",
       "      <td>0.717596</td>\n",
       "      <td>1.630</td>\n",
       "      <td>5629.021</td>\n",
       "      <td>7530.316</td>\n",
       "      <td>16462.360</td>\n",
       "      <td>23.716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225.715514</td>\n",
       "      <td>11.615215</td>\n",
       "      <td>0.807544</td>\n",
       "      <td>0.365931</td>\n",
       "      <td>0.604923</td>\n",
       "      <td>0.714978</td>\n",
       "      <td>1.611</td>\n",
       "      <td>5870.977</td>\n",
       "      <td>7759.470</td>\n",
       "      <td>15719.644</td>\n",
       "      <td>23.033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>996.458572</td>\n",
       "      <td>10.071615</td>\n",
       "      <td>0.830058</td>\n",
       "      <td>0.443281</td>\n",
       "      <td>0.665793</td>\n",
       "      <td>0.680747</td>\n",
       "      <td>1.743</td>\n",
       "      <td>7440.006</td>\n",
       "      <td>8320.351</td>\n",
       "      <td>16857.419</td>\n",
       "      <td>21.516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>951.599891</td>\n",
       "      <td>9.680111</td>\n",
       "      <td>0.835709</td>\n",
       "      <td>0.453393</td>\n",
       "      <td>0.673344</td>\n",
       "      <td>0.685272</td>\n",
       "      <td>1.717</td>\n",
       "      <td>7771.060</td>\n",
       "      <td>8569.443</td>\n",
       "      <td>16014.342</td>\n",
       "      <td>20.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>890.072701</td>\n",
       "      <td>9.264161</td>\n",
       "      <td>0.839427</td>\n",
       "      <td>0.463695</td>\n",
       "      <td>0.680951</td>\n",
       "      <td>0.693787</td>\n",
       "      <td>1.710</td>\n",
       "      <td>8207.277</td>\n",
       "      <td>8896.347</td>\n",
       "      <td>15309.346</td>\n",
       "      <td>20.185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      contrast  dissimilarity  homogeneity       ASM    energy  correlation  \\\n",
       "0  1246.643915      11.979190     0.799157  0.361724  0.601435     0.717596   \n",
       "1  1225.715514      11.615215     0.807544  0.365931  0.604923     0.714978   \n",
       "2   996.458572      10.071615     0.830058  0.443281  0.665793     0.680747   \n",
       "3   951.599891       9.680111     0.835709  0.453393  0.673344     0.685272   \n",
       "4   890.072701       9.264161     0.839427  0.463695  0.680951     0.693787   \n",
       "\n",
       "     SRE       LRE       GLU        RLU     RPC  class  \n",
       "0  1.630  5629.021  7530.316  16462.360  23.716      1  \n",
       "1  1.611  5870.977  7759.470  15719.644  23.033      1  \n",
       "2  1.743  7440.006  8320.351  16857.419  21.516      1  \n",
       "3  1.717  7771.060  8569.443  16014.342  20.925      1  \n",
       "4  1.710  8207.277  8896.347  15309.346  20.185      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conjunto de dados de EM\n",
    "EM_data = pd.read_csv('EM_metrics_mask.csv', index_col=0)\n",
    "EM_data['class'] = 1\n",
    "EM_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99be239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserindo o nome da Imagem no dataframe\n",
    "EM_data['image'] = pd.read_csv(\"EM_images.csv\", index_col=0).values\n",
    "\n",
    "#Separando o codigo dos pacientes através do nome na imagem\n",
    "EM_data['person'] = EM_data.apply(lambda x: x['image'].split('_')[0], axis=1)\n",
    "\n",
    "#Define o numero de pacientes que irão ser utilizados como teste\n",
    "number_of_groups_test = round(EM_data.person.nunique() * TEST_FACTOR)\n",
    "\n",
    "#Seleciona os pacientes que serão teste\n",
    "EM_test_pacients = EM_data.person.value_counts()[-number_of_groups_test:].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b69bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice do dataset em treino e teste conforme a lógica acima\n",
    "\n",
    "#Treino\n",
    "EM_train = EM_data.loc[~EM_data['person'].isin(EM_test_pacients)].iloc[:,:-2]\n",
    "\n",
    "#Teste\n",
    "EM_test = EM_data.loc[EM_data['person'].isin(EM_test_pacients)].iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60371090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0360faf",
   "metadata": {},
   "source": [
    "### Conjunto de dados AVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5939dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrast</th>\n",
       "      <th>dissimilarity</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>ASM</th>\n",
       "      <th>energy</th>\n",
       "      <th>correlation</th>\n",
       "      <th>SRE</th>\n",
       "      <th>LRE</th>\n",
       "      <th>GLU</th>\n",
       "      <th>RLU</th>\n",
       "      <th>RPC</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1575.100975</td>\n",
       "      <td>19.506832</td>\n",
       "      <td>0.636643</td>\n",
       "      <td>0.207171</td>\n",
       "      <td>0.455161</td>\n",
       "      <td>0.883374</td>\n",
       "      <td>1.689</td>\n",
       "      <td>1798.881</td>\n",
       "      <td>3501.078</td>\n",
       "      <td>28358.894</td>\n",
       "      <td>39.208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1507.389078</td>\n",
       "      <td>19.579652</td>\n",
       "      <td>0.630842</td>\n",
       "      <td>0.207477</td>\n",
       "      <td>0.455496</td>\n",
       "      <td>0.891828</td>\n",
       "      <td>1.691</td>\n",
       "      <td>1833.233</td>\n",
       "      <td>3492.157</td>\n",
       "      <td>28625.825</td>\n",
       "      <td>39.316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1288.668041</td>\n",
       "      <td>18.183973</td>\n",
       "      <td>0.642326</td>\n",
       "      <td>0.224194</td>\n",
       "      <td>0.473491</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>1.626</td>\n",
       "      <td>2016.729</td>\n",
       "      <td>3647.280</td>\n",
       "      <td>26321.974</td>\n",
       "      <td>37.666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111.119427</td>\n",
       "      <td>16.685142</td>\n",
       "      <td>0.659915</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.911819</td>\n",
       "      <td>1.551</td>\n",
       "      <td>2338.977</td>\n",
       "      <td>3928.393</td>\n",
       "      <td>23145.349</td>\n",
       "      <td>34.988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969.727427</td>\n",
       "      <td>16.020518</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>0.193310</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>0.903644</td>\n",
       "      <td>1.450</td>\n",
       "      <td>1876.947</td>\n",
       "      <td>3869.643</td>\n",
       "      <td>21385.778</td>\n",
       "      <td>35.493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      contrast  dissimilarity  homogeneity       ASM    energy  correlation  \\\n",
       "0  1575.100975      19.506832     0.636643  0.207171  0.455161     0.883374   \n",
       "1  1507.389078      19.579652     0.630842  0.207477  0.455496     0.891828   \n",
       "2  1288.668041      18.183973     0.642326  0.224194  0.473491     0.905488   \n",
       "3  1111.119427      16.685142     0.659915  0.242424  0.492366     0.911819   \n",
       "4   969.727427      16.020518     0.646192  0.193310  0.439671     0.903644   \n",
       "\n",
       "     SRE       LRE       GLU        RLU     RPC  class  \n",
       "0  1.689  1798.881  3501.078  28358.894  39.208      0  \n",
       "1  1.691  1833.233  3492.157  28625.825  39.316      0  \n",
       "2  1.626  2016.729  3647.280  26321.974  37.666      0  \n",
       "3  1.551  2338.977  3928.393  23145.349  34.988      0  \n",
       "4  1.450  1876.947  3869.643  21385.778  35.493      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conjunto de dados com AVC\n",
    "AVC_data = pd.read_csv('AVC_metrics_mask.csv', index_col=0)\n",
    "AVC_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafb7751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrast</th>\n",
       "      <th>dissimilarity</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>ASM</th>\n",
       "      <th>energy</th>\n",
       "      <th>correlation</th>\n",
       "      <th>SRE</th>\n",
       "      <th>LRE</th>\n",
       "      <th>GLU</th>\n",
       "      <th>RLU</th>\n",
       "      <th>RPC</th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1575.100975</td>\n",
       "      <td>19.506832</td>\n",
       "      <td>0.636643</td>\n",
       "      <td>0.207171</td>\n",
       "      <td>0.455161</td>\n",
       "      <td>0.883374</td>\n",
       "      <td>1.689</td>\n",
       "      <td>1798.881</td>\n",
       "      <td>3501.078</td>\n",
       "      <td>28358.894</td>\n",
       "      <td>39.208</td>\n",
       "      <td>0</td>\n",
       "      <td>001_FLAIR18_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1507.389078</td>\n",
       "      <td>19.579652</td>\n",
       "      <td>0.630842</td>\n",
       "      <td>0.207477</td>\n",
       "      <td>0.455496</td>\n",
       "      <td>0.891828</td>\n",
       "      <td>1.691</td>\n",
       "      <td>1833.233</td>\n",
       "      <td>3492.157</td>\n",
       "      <td>28625.825</td>\n",
       "      <td>39.316</td>\n",
       "      <td>0</td>\n",
       "      <td>001_FLAIR19_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1288.668041</td>\n",
       "      <td>18.183973</td>\n",
       "      <td>0.642326</td>\n",
       "      <td>0.224194</td>\n",
       "      <td>0.473491</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>1.626</td>\n",
       "      <td>2016.729</td>\n",
       "      <td>3647.280</td>\n",
       "      <td>26321.974</td>\n",
       "      <td>37.666</td>\n",
       "      <td>0</td>\n",
       "      <td>001_FLAIR20_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111.119427</td>\n",
       "      <td>16.685142</td>\n",
       "      <td>0.659915</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.911819</td>\n",
       "      <td>1.551</td>\n",
       "      <td>2338.977</td>\n",
       "      <td>3928.393</td>\n",
       "      <td>23145.349</td>\n",
       "      <td>34.988</td>\n",
       "      <td>0</td>\n",
       "      <td>001_FLAIR21_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969.727427</td>\n",
       "      <td>16.020518</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>0.193310</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>0.903644</td>\n",
       "      <td>1.450</td>\n",
       "      <td>1876.947</td>\n",
       "      <td>3869.643</td>\n",
       "      <td>21385.778</td>\n",
       "      <td>35.493</td>\n",
       "      <td>0</td>\n",
       "      <td>002_FLAIR21_mask.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      contrast  dissimilarity  homogeneity       ASM    energy  correlation  \\\n",
       "0  1575.100975      19.506832     0.636643  0.207171  0.455161     0.883374   \n",
       "1  1507.389078      19.579652     0.630842  0.207477  0.455496     0.891828   \n",
       "2  1288.668041      18.183973     0.642326  0.224194  0.473491     0.905488   \n",
       "3  1111.119427      16.685142     0.659915  0.242424  0.492366     0.911819   \n",
       "4   969.727427      16.020518     0.646192  0.193310  0.439671     0.903644   \n",
       "\n",
       "     SRE       LRE       GLU        RLU     RPC  class                 image  \n",
       "0  1.689  1798.881  3501.078  28358.894  39.208      0  001_FLAIR18_mask.png  \n",
       "1  1.691  1833.233  3492.157  28625.825  39.316      0  001_FLAIR19_mask.png  \n",
       "2  1.626  2016.729  3647.280  26321.974  37.666      0  001_FLAIR20_mask.png  \n",
       "3  1.551  2338.977  3928.393  23145.349  34.988      0  001_FLAIR21_mask.png  \n",
       "4  1.450  1876.947  3869.643  21385.778  35.493      0  002_FLAIR21_mask.png  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVC_data['image'] = pd.read_csv(\"AVC_images.csv\", index_col=0).values\n",
    "AVC_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49673d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando o codigo dos pacientes através do nome na imagem\n",
    "AVC_data['person'] = AVC_data.apply(lambda x: x['image'].split('_')[0], axis=1)\n",
    "\n",
    "#Define o numero de pacientes que irão ser utilizados como teste\n",
    "number_of_groups_test = round(AVC_data.person.nunique() * TEST_FACTOR)\n",
    "\n",
    "#Seleciona os pacientes que serão teste\n",
    "AVC_data_pacients = AVC_data.person.value_counts()[-number_of_groups_test:].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "971900af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice do dataset em treino e teste conforme a lógica acima\n",
    "\n",
    "#Treino\n",
    "AVC_train = AVC_data.loc[~AVC_data['person'].isin(AVC_data_pacients)].iloc[:,:-2]\n",
    "\n",
    "#Teste\n",
    "AVC_test = AVC_data.loc[AVC_data['person'].isin(AVC_data_pacients)].iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13eac95",
   "metadata": {},
   "source": [
    "Foi construída uma lógica para que a validação e teste não misturem dados de pacientes, logo, um paciente será treinamento ou teste, não irá existe fatias de uma paciente de treino no conjunto de teste.\n",
    "<br><br>\n",
    "Outro ponto é que a proporção de 70/30 representa a quantidade de pacientes de cada conjunto e não a quantidade de dados, pois, alguns pacientes possuem mais fatias presentes no conjunto do que outros, tornando a divisão pela quantidade de pacientes mais plausível."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028510e8",
   "metadata": {},
   "source": [
    "### Unindo conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed40af",
   "metadata": {},
   "source": [
    "Os dados são após lidos são unidos em um único conjunto de dados *DataFrame* contendo $1048$ amostras com $11$ características extraídas (*features*) e a classe de cada amostra.\n",
    "<br>\n",
    "<br>\n",
    "A normalização dos dados foi realizada após a unificação, para que a escala possa representar ambas as classes e não ficar somente focada em uma (normalizar os dados após a unificação apresentou ganho de 1% em acurácia nos dados de validação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9f01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de ambas as classes\n",
    "#Treino\n",
    "df_both_class_train = pd.concat([EM_train, AVC_train])\n",
    "\n",
    "#Teste\n",
    "df_both_class_test = pd.concat([EM_test, AVC_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38cb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalizando os dados unidos\n",
    "# df_both_class = normalize_df(df_both_class_train)\n",
    "\n",
    "# df_both_class_test = normalize_df(df_both_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba244bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "349d74cf",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae40d99",
   "metadata": {},
   "source": [
    "Os dados foram separados em conjunto de treinamento e validação em uma proporção de 70/30, assim 70% dos dados foram alocados para serem utilizadas para treinar a nosso classificador baseado em SVM, enquanto 30% foi utilizado para validar a capacidade de generalização do modelo.\n",
    "<br>\n",
    "<br>\n",
    "Para que o conjunto gerado seja sempre o mesmo foi utilizado uma semente fixa de 2022, garantindo a replicabilidade do experimento, outro ponto a se atentar é a estratificação dos conjuntos, assim tornando a distribuição das amostras positivas e negativas (AVC e EM) igualitária entre treino e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08c6a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando dados de teste\n",
    "X_train = df_both_class.iloc[:,:-1]\n",
    "y_train = df_both_class['class'].values.ravel()\n",
    "\n",
    "#Separando dados de treino\n",
    "X_test = df_both_class_test.iloc[:,:-1]\n",
    "y_test = df_both_class_test['class'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc45d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorando warnwings do treinamento\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1c617",
   "metadata": {},
   "source": [
    "## Preparando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7ff52",
   "metadata": {},
   "source": [
    "Visando gerar um modelo robusto foi realizado a otimização dos parâmetros de treinamento através da técnica de busca em grande (*Grid Search*), essa técnica treina o modelo com diversas combinações de parâmetros e seleciona aqueles que apresentaram uma qualidade melhor (conforme o teste com a métrica selecionada).\n",
    "<br>\n",
    "<br>\n",
    "Nosso modelo durante o treinamento foi avaliado através da sua precisão, revocação e acurácia balanceada, junto do método *classification_report* que permite uma visualização direta desses valores ao final do treinamento, além da evolução da qualidade conforme os parâmetros foram testados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6e90473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c2fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n",
    "    {\"kernel\": [\"linear\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67f0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\"precision\",  \"balanced_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f01f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbda2b",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe75de",
   "metadata": {},
   "source": [
    "O treinamento basicamente ocorre uma vez para cada método de avaliação definido na lista *scores* e através do *GridSearch* busca a melhor configuração dos parâmetros para o SVM, ao final do treinamento o resultado é apresentado para cada um dos *scores* demonstrando a qualidade por interação do *GridSeach*.\n",
    "<br>\n",
    "<br>\n",
    "Como resultado do treinamento algumas combinações apresentaram 100% de acurácia (ou outra métrica que estava sendo utilizada na interação) no conjunto de treino, mostrando assim que é possível separar os conjuntos através de uma representação linear (considerando que durante o ajuste fino dos parâmetros foi selecionado o *Kernel* linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c487cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.520 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.520 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.026) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.520 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.009) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.009) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.009) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.009) for {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.998 (+/-0.009) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.990 (+/-0.021) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.009) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.990 (+/-0.021) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.005) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.998 (+/-0.009) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.999 (+/-0.005) for {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.999 (+/-0.005) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exemplo de fine tunning obtido do tutorial do SKlearn para finetunning\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tuned_parameters, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_[\"mean_test_score\"]\n",
    "    stds = clf.cv_results_[\"std_test_score\"]\n",
    "    \n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print()\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print()\n",
    "#     y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a1c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c77a41",
   "metadata": {},
   "source": [
    "## Testando qualidade com a validação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d33ff8",
   "metadata": {},
   "source": [
    "Em posse do modelo treinado foi obtida a matriz de confusão e a acurácia balanceada do classificador, os resultados foram bem promissores com os dados de validação com uma acurácia de 100% e não comento erros na matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02778af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b205366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9208e6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acurácia balanceada para os dados de validação\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb669367",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67a0f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiro Negativo: 86 \n",
      "Falso Negativo: 0\n",
      "Falso Positivo: 0\n",
      "Verdadeiro Positivo: 77\n"
     ]
    }
   ],
   "source": [
    "#Matriz de confusão:\n",
    "tn, fp, fn, tp\n",
    "print(f\"Verdadeiro Negativo: {tn} \\nFalso Negativo: {fp}\\nFalso Positivo: {fn}\\nVerdadeiro Positivo: {tp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
